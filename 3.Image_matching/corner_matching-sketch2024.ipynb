{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> add your surname and name here!!!!!!</b>\n",
    "\n",
    "##  SURNAME: ________ NAME: _________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import division # uncomment this if using Python 2.7\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import signal, spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from skimage import data, color, img_as_float, img_as_ubyte, filters, feature, util, io\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature matching\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we are going to dive deeper into <i>image matching</i>, specifically on a local approach based on features correspondances. \n",
    "\n",
    "We first consider the simplest situation possible: the image pairs we consider are related by simple transformations, therefore we will make the following choices:\n",
    "1. Feature detector: corners (with the shi-tomasi algorithm)\n",
    "2. Feature description: patches around the corner (size $w\\times w$)\n",
    "3. Matching strategy: affinity matrix with a similarity measure of choice\n",
    "\n",
    "\n",
    "The parameters of every intermediate step, must be specified as input arguments. Try with different distance metrics (e.g. euclidean, correlation, squared euclidean) and with all three image pairs (Rubik, Shrub, Phone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us define the main functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first write a function that extracts patches of image around each corner (w.r.t. the patch size, that is a parameter)\n",
    "* First we need to pad our image, adding a surrounding frame of appropriate width. In this way even border features (like the red one in the drawing) will have their neighbourhood\n",
    "\n",
    "Then, for each corner, \n",
    "* we adjust the corner coordinates with respect to the new padded image I_ext\n",
    "* we extract the size_w X size_w patch surrounding the corner (check the range notation)\n",
    "* we flatten the patch to form a 1D feature vector of size 2*size_w and save it in a list\n",
    "\n",
    "\n",
    "<img src=\"week2_lab_notes.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_descriptor(I, corner_pos, size_w):\n",
    "    \"\"\"Extract square patches around each corner on an input grayscale image. \n",
    "    - I: input RGB image\n",
    "    - corner_pos: list with position of n corners (row,col)\n",
    "    - size_w: (integer) patch side\n",
    "   \"\"\"\n",
    "    \n",
    "    n = len(corner_pos) # Number of features\n",
    "    hw = int(np.floor(size_w/2)) # half size of the patch (useful to center the pat)\n",
    "    I_ext = np.pad(I, hw, 'reflect') # pad the image with a frame of width hw \n",
    "    \n",
    "    # initialize patches list\n",
    "    patches = np.zeros([n,(2*hw+1)**2])\n",
    "    \n",
    "    for i in range(0, n):\n",
    "        \n",
    "        r = corner_pos[i,0]+hw # adjust the row of each corner considering the padding\n",
    "        c = corner_pos[i,1]+hw # do the same for the column \n",
    "        tmp = I_ext[....FILL HERE.....] # estract the patch\n",
    "        patches[i,:] = tmp.flatten() #flatten the patch and save it in the patches list\n",
    "        \n",
    "    return patches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function that computes the feature matching procedure.\n",
    "Assuming we have $m$ features in image 1 and $n$ features in image 2, the affinity matrix will have size $m\\times n$.\n",
    "For each feature in image 1, we will be matching the one in image 2 <i>minimizes</i> the distance.\n",
    "\n",
    "Below you find a simple version of the procedure  \n",
    "1. First compute the affinity matrix \n",
    "2. Then detect the maxima of the affinity matrix\n",
    "3. Derive che corresponding matches\n",
    "4. Return the matches and the affinity matrix\n",
    "\n",
    "**Hint:** First check <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\">`spatial.distance.cdist`</a> from `scipy` module, with Euclidean metric.\n",
    "Then use the formulae below to compute the elements of an affinity matrix (values in the range [0,1]\n",
    "$\\exp^{-d(f_i,g_j)/2\\sigma^2}$ ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_matching(sigma, patches1, patches2,corner_pos1,corner_pos2):\n",
    "    \n",
    "    # evaluate the distance among patches [HERE WE ARE JUST USING THE APPEARANCE SIMILARITY]\n",
    "    D = spatial.distance.cdist(patches1,patches2, metric='euclidean')\n",
    "    # compute the affinity matrix using the exponent formulation\n",
    "    E = np.exp(-D//(2*sigma*sigma))\n",
    "    # find the minimum distace\n",
    "    argmaxE_h = np.argmax(E, axis=1)\n",
    "    argmaxE_v = np.argmax(E, axis=0)\n",
    "    match = []\n",
    "    \n",
    "    for i, amx in enumerate(argmaxE_h):\n",
    "        if argmaxE_v[amx] == i:    # maxima on rows and columns\n",
    "      \n",
    "    # plot the matching pairs (match includes the match from corner_pos2 associated with corner_pos1)\n",
    "    #match = corner_pos2[argmaxE,:]\n",
    "    \n",
    "    return E, match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that plots the images side-by-side and superimposes the features (<b>hint:</b> beware of the offset!) and a line connecting the matched pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_match(match,corner_pos1,corner_pos2,img1, img2):\n",
    "    \"\"\"show match on side-by-side images\"\"\"\n",
    "    \n",
    "    img= np.concatenate([img1,img2],axis=1)\n",
    "    plt.imshow(img, cmap=cm.gist_gray)\n",
    "    \n",
    "    for i in range(0, len(corner_pos1)):\n",
    "        plt.plot([corner_pos1[i,1], match[i,1]+img1.shape[1]], [corner_pos1[i,0], match[i,0]],'y')\n",
    "        \n",
    "    plt.scatter(corner_pos1[:,1], corner_pos1[:,0], s=10, c='r')\n",
    "    plt.scatter(corner_pos2[:,1]+img1.shape[1], corner_pos2[:,0], s=20, c='b')\n",
    "    \n",
    "    return img    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us test the feature matching pipeline\n",
    "\n",
    "We start with a simple image pair. We first load them and visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IMAGES\n",
    "RGBimg1 = io.imread('images/shrub_L.jpg')\n",
    "img1 = img_as_float(color.rgb2gray(RGBimg1))\n",
    "\n",
    "RGBimg2 = io.imread('images/shrub_R.jpg') #(See below)\n",
    "img2 = img_as_float(color.rgb2gray(RGBimg2))\n",
    " \n",
    "#PLOT THEM\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(RGBimg1, cmap=cm.gist_gray)\n",
    "plt.title('Image 1')\n",
    "plt.subplot(122)\n",
    "plt.imshow(RGBimg2, cmap=cm.gist_gray)\n",
    "plt.title('Image 2');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us identify the corners by using the shi tomasi algorithm implemented in skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE DETECTION\n",
    "# using the shi-tomasi algorithm, identify the corners in both images\n",
    "\n",
    "corners1 = feature.corner_peaks(feature.corner_shi_tomasi(img1)) # IT MAY BE WORTH ADDING num_peaks=300 to corner_peaks\n",
    "corners2 = feature.corner_peaks(feature.corner_shi_tomasi(img2)) # IT MAY BE WORTH ADDING num_peaks=300 to corner_peaks\n",
    "\n",
    "# plot the results on both images side by side\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(RGBimg1, cmap=cm.gist_gray)\n",
    "plt.scatter(corners1[:,1], corners1[:,0], s=30)\n",
    "plt.title('skimage.feature.corner_peaks result')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(RGBimg2, cmap=cm.gist_gray)\n",
    "plt.scatter(corners2[:,1], corners2[:,0], s=30, c='r')\n",
    "plt.title('skimage.feature.corner_peaks result');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE DESCRIPTORS\n",
    "# TRY WITH DIFFERENT WINDOW SIZES\n",
    "patches1 = patch_descriptor(img1, corners1, 40)\n",
    "patches2 = patch_descriptor(img2, corners2, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE MATCHING\n",
    "plt.figure(figsize=(12,6))\n",
    "D,match = spectral_matching(0.5,patches1, patches2, corners1, corners2)\n",
    "match_euclidean = show_match(match,corners1,corners2,img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LET US ALSO HAVE A LOOK AT THE AFFINITY MATRIX\n",
    "plt.imshow(D) \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "There are a number of improvement you could consider at some point. Below you find a mandatory improvement and some optional ones\n",
    "1.  The function spectral_matching does not compute the maxima in the correct way; <i>correct the function</i> so that the identified feature pairs are maxima of both rows and colums . \n",
    "\n",
    "Optionally you may also have a look at the following\n",
    "1. spectral_matching: you may add a threshold on the distance, setting to 0 the affinity matrix entries below a threshold(see theory)\n",
    "2. In the affinity matrix computation, one could also include an evaluation on the position of\n",
    "features (close features should be favoured if we have a prior on image similarity). Again, see theory\n",
    "2. Corners on the border of the image should be discarded as they tend to be less reliable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "Here are some experiments you should carry out. Add code snippets and comments below. Conclude with a final discussion section.\n",
    "- Debug n. 0 is to use the same image for img1 and img2. Answer before proceeding: what do you expect to find? Check the Affinity Matrix\n",
    "- How to proceed if you want to obtain fewer corners?\n",
    "- Now try out with two different images of the same object, again analyse the matches as well as the affinity matrix. Try out different sigma values: are the results in line with your expectations?  \n",
    "- now  \"break\" the simple matching procedure by applying appropriate image transformations: use, as inputs, I1 and transformed(I1), where transformed may be:\n",
    "    - small or large translations\n",
    "    - small or large rotations\n",
    "    - small or large zoom in\n",
    "\n",
    "- To be sure you fully grasp the concepts, you should try out other image pairs (see the Images folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code code code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add your final discussion here !\n",
    "Be concise and specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
